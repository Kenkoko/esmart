from modules import *
import tensorflow_addons as tfa

def train(config):
    model = get_model(config)
    train, val = get_dip(config, context="training")
    metrics = [
        'accuracy',
        tfa.metrics.F1Score(
            num_classes=len(get_labels()), 
            threshold=None, 
            average='macro'),
        PrecisionMultiClass(
            num_classes=len(get_labels()), 
            threshold=None, 
            average='macro'),
        RecallMultiClass(
            num_classes=len(get_labels()), 
            threshold=None, 
            average='macro'
        ),
    ]
    callbacks = [
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss', factor=0.2,
            patience=10, 
            min_lr=0.0001, 
            verbose=1,
            cooldown=2), ## https://stackoverflow.com/questions/51889378/how-to-use-keras-reducelronplateau
        tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10),
    ]
    model.compile(
        optimizer= get_optimizer("{{ optimizer }}", {{ learning_rate }}),
        loss= "{{ loss }}",
        metrics=metrics,
    )

    result = model.fit(
        train, 
        steps_per_epoch= {{ steps_per_epoch }}, 
        epochs= {{ max_epochs }},
        validation_data=val, 
        callbacks=callbacks, 
        verbose=1)

def get_optimizer(name, lr):
        if name == 'adam':
            optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
        elif name == 'adagrad':
            optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)
        elif name == 'sgd':
            optimizer = tf.keras.optimizers.SGD(learning_rate=lr)
        else:
            raise ValueError(
                "invalid value train.loss={}".format(name)
            )
        return optimizer